#pragma once
// ============================================================================
//  hal/vision.h — AI 视觉传感器接口（机器人的"眼睛"）
// ============================================================================
//
//  【这个文件干什么？】
//    AI 视觉传感器就是机器人的摄像头。它可以识别赛场墙壁上的
//    黑白方块图案——叫 AprilTag（长得像二维码，但更简单、更快识别）。
//    每个标签的位置在赛场上是固定的，所以看到标签就能算出
//    "我自己在赛场上的什么位置"。
//
//  【它每次"拍照"能看到什么？】
//    • 标签 ID    — 这是哪个标签（用来查找它在赛场上的已知坐标）
//    • 中心坐标   — 标签在图片里的位置（320×240 像素的图片）
//    • 大小       — 标签看起来有多大（像素）→ 越大说明离得越近
//    • 角度       — 标签相对摄像头的旋转角度
//
//  【图片坐标系】
//    图片左上角是 (0,0)，x 向右增大，y 向下增大。
//    摄像头装在机器人前方，摄像头偏移量在 config.h 里设定。
//
// ============================================================================
#include "hal/hal_log.h"

/// 每次拍照最多能返回的标签数量
constexpr int VISION_MAX_TAGS = 8;

/// 一个被检测到的 AprilTag 标签的全部信息
struct TagDetection {
    int    id;           ///< 标签 ID（用来查找这个标签在赛场上的已知坐标）
    double center_x;     ///< 标签在图片里的水平中心位置 [0, 320)
    double center_y;     ///< 标签在图片里的垂直中心位置 [0, 240)
    double width;        ///< 标签在图片里的宽度（像素）—— 越大=离得越近
    double height;       ///< 标签在图片里的高度（像素）
    double angle;        ///< 标签的旋转角度（度）
    bool   valid;        ///< true = 有效检测，false = 无效/空的
};

/// 初始化 AI 视觉传感器，启用 AprilTag 检测模式（开机时调用一次）
void vision_init();

/// "拍一张照"，返回这次拍到了几个 AprilTag 标签
/// 拍照结果存在内部缓冲区里，用 vision_get_tag(i) 来取第 i 个
/// @return 检测到的标签数量（0 ~ VISION_MAX_TAGS）
int vision_snapshot();

/// 从最近一次拍照结果中取出第 index 个标签的信息
/// @param index  从 0 开始的索引（必须 < vision_snapshot() 返回的数量）
/// @return 标签信息结构体（使用前先检查 .valid 是否为 true）
TagDetection vision_get_tag(int index);

/// 检查视觉传感器是否已连接并正常工作
bool vision_is_connected();
